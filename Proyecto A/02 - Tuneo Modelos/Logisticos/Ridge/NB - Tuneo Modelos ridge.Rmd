---
title: "NB - Tuneo Modelos"
output: html_document
---

https://topepo.github.io/caret/index.html
https://www.cienciadedatos.net/documentos/41_machine_learning_con_r_y_caret

# Paquetes

```{r}
library(caret)
library(readr)
library(dplyr)
library(ggplot2)
```


```{r}
# Linux
data <- read_csv('Proyecto A/00 - Creación Dataset y Variables/Dataset_Modelos.csv')
```

```{r}
# Windows
data <- read_csv('../00 - Creación Dataset y Variables/Dataset_Modelos.csv')
```

Borramos las variables de caracteres.

```{r}
char_vars <- c("X1", 
               "url", 
               "scheme", 
               "domain_complete", 
               "domain", 
               "subdomain", 
               "suffix", 
               "domain_subdomain", 
               "path", 
               "suffix2")

df <- data %>%
  select(-char_vars)
```



```{r}
names(df)
```

Partimos el dataset en partición de Train y Test. El objeto *train_index* tendrá el índice de el Train set.

```{r}
set.seed(45)
train_index <- createDataPartition(y = df$phishing, times = 1, p = 0.80, list = FALSE)

train <- df[train_index,]
test <- df[-train_index,]

train <- train %>%
  mutate(phishing = factor(phishing, labels = c("NoPhish", "Phish")))
test <- test %>%
  mutate(phishing = factor(phishing, labels = c("NoPhish", "Phish")))

#test1 <- df[-train_index,]

#test_index <- createDataPartition(y = test1$phishing, times = 1, p = 0.5, list = FALSE)

#test <- test1[test_index,]
#validation <- test1[-test_index,]
```

Armamos los folds de Cross-Validation, usamos k = 5. El objeto *resample_method* tendrá toda la información de las particiones de Cross-Validation que realizamos.

```{r}
set.seed(53)
k = 5
CV_folds <- createFolds(train$phishing, k = k, list = TRUE)

resample_method <- trainControl(method = "cv",
                                number = k,
                                classProbs = TRUE,
                                summaryFunction = twoClassSummary,
                                verboseIter = TRUE,
                                returnData = TRUE,
                                returnResamp = "final",
                                savePredictions = "final",
                                search = "grid",
                                index = CV_folds)

```
```{r}
set.seed(53)
k = 5
CV_folds <- createFolds(train$phishing, k = k, list = TRUE)

TrainControl <- trainControl(method = "none",
                                classProbs = TRUE,
                                allowParallel= TRUE)

```

En esta parte armamos el dataset con los valores de los hiperparámetros que vamos a probar. Importante: Las columnas tienen que llevar el nombre de los hiperparámetros de ese modelo en el método (paquete) empleado.

```{r}
ridge_grid <- expand.grid(alpha = 0,
                          lambda = 0.01)


dim(ridge_grid)
head(ridge_grid)
```

Corriendo esta celda se realiza Cross-Validation probando todas las combinaciones de hiperparámetros que determinamos previamente y se entrena el modelo final con todos los datos del Train set y con el set de hiperparámetros óptimos.

```{r}
ridge <- train(as.factor(phishing)~., 
               data = train, 
               method = "glmnet", 
               trControl = TrainControl,
               verbose = TRUE,
               tuneGrid = ridge_grid,
               #tuneLength = 50,
               preProcess = c("center", "scale"),
               metric = "ROC")
```

Imprimimos los resultados obtenidos por Cross-Validation.
```{r}
plot(ridge, metric= "ROC")
plot(ridge, metric= "Spec")#ES SENSITIVITY
plot(ridge, metric= "Sens")#ES Specificity
```

```{r}
ridge
```

```{r}
ridge$bestTune
```

```{r}
ridge$preProcess
```
```{r}
ridge$results
```



```{r}
plot(ridge$finalModel, xvar = "lambda")
```

```{r}
ggplot(ridge$results, aes(x=lambda, y = Spec))+
  geom_point()+
  geom_line()+
  expand_limits(y = c(0,1))+
  theme_bw()
```


```{r}
dim(test)
```


Matriz de Confusión del modelo entrenado con el set de Test.

```{r}
confusionMatrix(data = as.factor(predict(ridge, test)),
                reference = as.factor(test$phishing),
                positive = "Phish",
                mode = "everything")
```

# Guardar Resultados

En esta parte guardamos los resultados de la optimización de hiperparámetros mediante Cross-Validation. La celda comentada sirve para crear el archivo csv por primera vez. Una vez creado dejarla comentada y correr solamente la última celda para incluir los nuevos resultados.

**REEMPLAZAR EL NOMBRE DEL MODELO**
```{r}
getwd()
```

```{r}
ridge$results
write_csv(ridge$results, file = 'ridge roc.csv')
```

```{r}
df_results <- read_csv("ridge roc.csv")
df_results <- rbind(df_results, ridge$results)
write_csv(df_results, file = "ridge roc.csv")
```
```{r}
df_results<-ridge$results
write_csv(df_results, file = "ridge roc.csv",append = T)
```

# Graficos del training
```{r}
ridge_results <- read_csv('ridge roc.csv')
lasso_results <- read_csv('lasso roc.csv')
resultados<-rbind(ridge_results[,0:8],lasso_results[,0:8])
resultados<-resultados%>%
  mutate(alpha=as.factor(ifelse(alpha==0, 'Ridge','Lasso')))%>%
  filter(lambda<0.25, lambda>0.01)
#plot<-resultados %>%
  #filter(lambda>=0, lambda<=0.1
         #,max.depth!=0
         #,ROC>0.933
         #,min.node.size==c(30)
         #,mtry %in% c(1,2,5,150)
         #,mtry==c(5,70,150)
         #)
ggplot(resultados, aes(x=lambda, y = Spec,
                          color=as.factor(alpha)
                          ))+
  geom_point(size=1,position=position_jitter(h=0, w=0))+
  #geom_smooth()+
  geom_line()+
  expand_limits(x=c(0.01,0.25))+
  labs(title = "Resultados Métrica Sens",
       subtitle = "Regresion Logistica  con 5 folds de Cross Validation",
       x = "Lambda", y="Sens",
       #shape = "Número de Árboles",
       color = "Regularizacion")+
  theme_bw()
```

```{r}
getwd()
saveRDS(ridge, "Ridge.rds")
```

