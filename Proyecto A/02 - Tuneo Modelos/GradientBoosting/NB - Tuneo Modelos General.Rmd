---
title: "NB - Tuneo Modelos"
output: html_document
---

https://topepo.github.io/caret/index.html
https://www.cienciadedatos.net/documentos/41_machine_learning_con_r_y_caret

http://uc-r.github.io/gbm_regression


# Paquetes

```{r}
library(caret)
library(readr)
library(dplyr)
library(ggplot2)
```


```{r}
# Linux
data <- read_csv('Proyecto A/00 - Creación Dataset y Variables/Dataset_Modelos.csv')
```

```{r}
table(data$phishing)
```


```{r}
# Windows
#data <- read_csv('../00 - Creación Dataset y Variables/Dataset_Modelos.csv')
```

Borramos las variables de caracteres.

```{r}
char_vars <- c("X1", 
               "url", 
               "scheme", 
               "domain_complete", 
               "domain", 
               "subdomain", 
               "suffix", 
               "domain_subdomain", 
               "path", 
               "suffix2")

df <- data %>%
  select(-char_vars)
```



```{r}
names(data_model)
```

Partimos el dataset en partición de Train y Test. El objeto *train_index* tendrá el índice de el Train set.

```{r}
set.seed(45)
train_index <- createDataPartition(y = df$phishing, times = 1, p = 0.80, list = FALSE)

train <- df[train_index,]
test <- df[-train_index,]

train <- train %>%
  mutate(phishing = factor(phishing, labels = c("NoPhish", "Phish")))
test <- test %>%
  mutate(phishing = factor(phishing, labels = c("NoPhish", "Phish")))


#test1 <- df[-train_index,]

#test_index <- createDataPartition(y = test1$phishing, times = 1, p = 0.5, list = FALSE)

#test <- test1[test_index,]
#validation <- test1[-test_index,]
```

```{r}
train$phishing
df$phishing[train_index]
```


Armamos los folds de Cross-Validation, usamos k = 5. El objeto *resample_method* tendrá toda la información de las particiones de Cross-Validation que realizamos.

```{r}
set.seed(53)
k = 5
CV_folds <- createFolds(train$phishing, k = k, list = TRUE)

resample_method <- trainControl(method = "cv",
                                number = k,
                                classProbs = TRUE,
                                summaryFunction = twoClassSummary,
                                verboseIter = TRUE,
                                returnData = TRUE,
                                returnResamp = "final",
                                savePredictions = "final",
                                search = "grid",
                                index = CV_folds)

```

En esta parte armamos el dataset con los valores de los hiperparámetros que vamos a probar. Importante: Las columnas tienen que llevar el nombre de los hiperparámetros de ese modelo en el método (paquete) empleado.

```{r}
gbm$results %>% arrange(desc(ROC))
```


```{r}
# Todavia no probadas estas combinaciones.
gbm_grid <- expand.grid(n.trees = c(150, 200),
                        interaction.depth = c(16, 18, 20),
                        shrinkage = c(0.15, 0.16),
                        n.minobsinnode = c(20))


dim(gbm_grid)
head(gbm_grid)
```


Corriendo esta celda se realiza Cross-Validation probando todas las combinaciones de hiperparámetros que determinamos previamente y se entrena el modelo final con todos los datos del Train set y con el set de hiperparámetros óptimos.

```{r}
gbm <- train(phishing~., 
             data = train, 
             method = "gbm", 
             trControl = resample_method,
             verbose = TRUE,
             tuneGrid = gbm_grid,
             #tuneLength = 50,
             #preProcess = c("center", "scale"),
             metric = "ROC")
```



Imprimimos los resultados obtenidos por Cross-Validation.

```{r}
gbm
```

```{r}
gbm$bestTune
```

```{r}
plot(gbm, metric = "ROC")
```

```{r}
plot(gbm, metric = "ROC", plotType = "level")
```

```{r, fig.height=8, fig.width=8}
ggplot(gbm$results, aes(x=interaction.depth, y = ROC, color = as.factor(shrinkage), shape = as.factor(n.trees)))+
  geom_point(size = 2)+
  #geom_line()+
  #expand_limits(y = c(0,1))+
  theme_bw()
```

```{r}
gbm$results %>%
  arrange(desc(ROC))
```





```{r}
dim(test)
```


Matriz de Confusión del modelo entrenado con el set de Test.

```{r}
confusionMatrix(data = as.factor(predict(gbm, train)),
                reference = as.factor(train$phishing),
                positive = "Phish",
                mode = "everything")
```


```{r}
confusionMatrix(data = as.factor(predict(gbm, test)),
                reference = as.factor(test$phishing),
                positive = "Phish",
                mode = "everything")
```


# Guardar Resultados

En esta parte guardamos los resultados de la optimización de hiperparámetros mediante Cross-Validation. La celda comentada sirve para crear el archivo csv por primera vez. Una vez creado dejarla comentada y correr solamente la última celda para incluir los nuevos resultados.

**REEMPLAZAR EL NOMBRE DEL MODELO**

```{r}
#write_csv(gbm$results, file = "Proyecto A/02 - Tuneo Modelos/GradientBoosting/GBM.csv")
```

```{r}
df_results <- read_csv("Proyecto A/02 - Tuneo Modelos/GradientBoosting/GBM.csv")
df_results <- rbind(df_results, gbm$results)
write_csv(df_results, file = "Proyecto A/02 - Tuneo Modelos/GradientBoosting/GBM.csv")
```


```{r}
df_results <- read_csv("Proyecto A/02 - Tuneo Modelos/GradientBoosting/GBM_Complete.csv")
```


```{r}
names(df_results)
```


```{r, fig.height=7, fig.width=10}
df_results %>%
  filter(ROC > 0.925,
         n.minobsinnode == 20) %>%
  ggplot(aes(x = interaction.depth, y = ROC, color = as.factor(shrinkage), shape = as.factor(n.trees)))+
  geom_point(size = 3)+
  #geom_smooth(se = FALSE)+
  geom_line()+
  labs(title = "Resultados Métrica ROC",
       subtitle = "Resultados de la métrica ROC para el modelo Gradient Boosting con 5-fold Cross Validation",
       x = "Profundidad del Árbol",
       shape = "Número de Árboles",
       color = "Paso de Aprendizaje")+
  theme_bw()
```


```{r}
df_results %>%
ggplot(aes(x=max.depth, y = ROC,color=as.factor(mtry)))+
  geom_point(size=3,position=position_jitter(h=0, w=3))+
  #geom_smooth()+
  #geom_line()+
  #expand_limits(y = c(0,1))+
  theme_bw()
```











