---
title: "NB - Tuneo Modelos"
output: html_document
---

https://topepo.github.io/caret/index.html
https://www.cienciadedatos.net/documentos/41_machine_learning_con_r_y_caret

# Paquetes

```{r}
library(caret)
library(readr)
library(dplyr)
library(ggplot2)
library(cowplot)
```


```{r}
# Linux
data <- read_csv('Proyecto A/00 - Creación Dataset y Variables/Dataset_Modelos.csv')
```

```{r}
# Windows
data <- read_csv('../00 - Creación Dataset y Variables/Dataset_Modelos.csv')
```

Borramos las variables de caracteres.

```{r}
char_vars <- c("X1", 
               "url", 
               "scheme", 
               "domain_complete", 
               "domain", 
               "subdomain", 
               "suffix", 
               "domain_subdomain", 
               "path", 
               "suffix2")

df <- data %>%
  select(-char_vars)
```



```{r}
names(data_model)
```

Partimos el dataset en partición de Train y Test. El objeto *train_index* tendrá el índice de el Train set.

```{r}
set.seed(35)
train_index <- createDataPartition(y = df$phishing, times = 1, p = 0.80, list = FALSE)

train <- df[train_index,]
test <- df[-train_index,]

train <- train %>%
  mutate(phishing = factor(phishing, labels = c("NoPhish", "Phish")))
test <- test %>%
  mutate(phishing = factor(phishing, labels = c("NoPhish", "Phish")))

#test1 <- df[-train_index,]

#test_index <- createDataPartition(y = test1$phishing, times = 1, p = 0.5, list = FALSE)

#test <- test1[test_index,]
#validation <- test1[-test_index,]
```

Armamos los folds de Cross-Validation, usamos k = 5. El objeto *resample_method* tendrá toda la información de las particiones de Cross-Validation que realizamos.

```{r}
set.seed(35)
k = 5
CV_folds <- createFolds(train$phishing, k = k, list = TRUE)

fitControl <- trainControl(method = "none",
                                classProbs = TRUE,
                                allowParallel = TRUE
                                ) 

```

En esta parte armamos el dataset con los valores de los hiperparámetros que vamos a probar. Importante: Las columnas tienen que llevar el nombre de los hiperparámetros de ese modelo en el método (paquete) empleado.

```{r}
C_range =    c(0.6)
sigma_range =  c(0.0025)

SVC_grid <- expand.grid(C= C_range,sigma=sigma_range)

```

Reducimos el train set porque tarda demasiado.
```{r}
#train_index2 <- createDataPartition(y = train$phishing, times = 1, p = 0.15, list = FALSE)
#train2 <- train[train_index2,]
```

Corriendo esta celda se realiza Cross-Validation probando todas las combinaciones de hiperparámetros que determinamos previamente y se entrena el modelo final con todos los datos del Train set y con el set de hiperparámetros óptimos.
```{r}
SVC <- train(as.factor(phishing)~., 
             data = train, 
             method = "svmRadial", 
             trControl = fitControl,
             verbose = TRUE,
             tuneGrid = SVC_grid,
             #tuneLength = 50,
             preProcess = c("center", "scale"),
             metric = "ROC")
```







```{r}
saveRDS(SVC, "SVCR.rds")
```

Imprimimos los resultados obtenidos por Cross-Validation.

```{r}
SVC
```
```{r}
plot(SVC, metric= "ROC")
plot(SVC, metric= "Spec")#ES SENSITIVITY
plot(SVC, metric= "Sens")#ES Specificity
```

```{r}
SVC$bestTune
```

```{r}
SVC$preProcess
```



```{r}
plot(ridge$finalModel, xvar = "lambda")
```

```{r}
ggplot(ridge$results, aes(x=lambda, y = Accuracy))+
  geom_point()+
  geom_line()+
  expand_limits(y = c(0,1))+
  theme_bw()
```


```{r}
dim(test)
```


Matriz de Confusión del modelo entrenado con el set de Test.

```{r}
confusionMatrix(data = as.factor(predict(ridge, test)),
                reference = as.factor(test$phishing),
                positive = "1",
                mode = "everything")
```

# Guardar Resultados

En esta parte guardamos los resultados de la optimización de hiperparámetros mediante Cross-Validation. La celda comentada sirve para crear el archivo csv por primera vez. Una vez creado dejarla comentada y correr solamente la última celda para incluir los nuevos resultados.

**REEMPLAZAR EL NOMBRE DEL MODELO**

```{r}
#write_csv(SVC$results,file="SVC.csv")
```

```{r}
df_results <- read_csv("SVC.csv")
df_results <- rbind(df_results, SVC$results)
#write_csv(df_results, file = "SVC.csv")
```


```{r}
df_results[order(df_results[,3],decreasing=TRUE),]
```





```{r}
plot(df_results$sigma,df_results$ROC)
plot(log(df_results$C),df_results$ROC)
plot(log(df_results$C),df_results$sigma)



plot1 <- ggplot(df_results, aes(x=log(C), y=ROC))+
  geom_point(size=3, position=position_jitter(h=0,w=3))+
  theme_bw()+
  labs(x="Log(C)",
       y="ROC")+
  theme(legend.position="none")
plot1
plot2 <- ggplot(df_results, aes(x=log(C), y=Sens))+
  geom_point(size=3, position=position_jitter(h=0,w=3))+
  theme_bw()+
  labs(x="Log(C)",
       y="Spec")+
  theme(legend.position="none")
plot3 <- ggplot(df_results, aes(x=log(C), y=Spec))+
  geom_point(size=3, position=position_jitter(h=0,w=3))+
  theme_bw()+
  labs(x="Log(C)",
       y="Sens")+
  theme(legend.position="none")
plot_grid(plot1, plot2, plot3)
```
```{r}
with(df_results, symbols(x=log(C), y=sigma, circles=ROC))
```


